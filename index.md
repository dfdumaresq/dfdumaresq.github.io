---
layout: default
title: "Home"
---

# Dave Dumaresq

Software engineer and AI safety researcher at SFU.  
Thirty-plus years building backend systems and, more recently, working on AI safety, interpretability, and governance tools.

## Current focus

- AI safety projects: AI fingerprinting, agent evaluations, and governance tooling.
- Teaching and mentoring on transformative AI, RLHF, and robust agents.
- Connecting software engineering practice with safety and reliability concerns.

## Selected projects

### AI Fingerprint

A project exploring ways to identify and verify AI-generated behavior and artifacts to support governance and accountability.

- Focus: AI agent fingerprinting, evaluations, and safety tooling.
- Role: Concept, design, and implementation.
- Links: <!-- TODO: add GitHub or docs links -->

### Virtues AI

An experiment in framing AI system behavior and evaluation around virtue-ethics-inspired principles.

- Focus: AI behavior evaluation & alignment concepts.
- Role: Design, prototyping, and evaluation.
- Links: <!-- TODO: add links -->

### Kaggle: Deep Past

Applied machine learning to historical or archaeological-style data (Kaggle project "deep past").

- Focus: Practical ML pipeline, feature engineering, evaluation.
- Role: End-to-end modeling and analysis.
- Links: <!-- TODO: add Kaggle link -->

### Swiss lakes munitions proposal

Used AI tools to support a proposal on removing legacy munitions from Swiss lakes.

- Focus: Research synthesis, scenario analysis, and communication.
- Role: Authoring, modeling scenarios, and drafting materials.
- Links: <!-- TODO: add PDF or writeup -->

### Stage play: *The Golden Goose is Near*

Stage play work supported by AI for dramaturgy and iteration.

- Focus: Story structure, dialogue exploration, and thematic development.
- Role: Playwright; used AI as a creative assistant.
- Links: <!-- TODO: add script or info link -->

## Work, teaching, and research

- Faculty at Simon Fraser University (SFU), teaching and mentoring in software engineering and AI-related topics.
- Completed and taught AI safety coursework, including RLHF, interpretability, robust agents, and evaluations.
- Ongoing work on backend resilience, caching, and verification patterns.

For a more detailed view, see my CV: <!-- TODO: add CV PDF link -->

## For collaborators

If you are interested in:

- AI safety evaluations or agent fingerprinting
- Governance and accountability tooling
- Applying strong software engineering practices to AI systems

feel free to reach out.

## Contact and links

- Email: <!-- TODO: add email or contact form link -->
- GitHub: <!-- TODO: add GitHub profile -->
- SFU profile: <!-- TODO: add SFU link -->
- Other links: <!-- TODO: add LinkedIn, Google Scholar, etc. -->
